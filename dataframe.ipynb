{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='800000'>Collect Data and Construct Data Frame</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import datetime\n",
    "from abrev import us_state_abbrev #made a file that has dictionary of states, with keys as whole names, and values as abreviations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Make a function that makes a data frame given a year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dataframe(year):\n",
    "    ##################### Read drug arrests by state excel files #############################\n",
    "    #read the excel files labeled years\n",
    "    df = pd.read_excel('drug_arrest/{}.xls'.format(year), skiprows = 3)\n",
    "    \n",
    "    #rename the column of interest to something concise\n",
    "    df.columns; #do this to see the exact syntax for column of interest\n",
    "    df = df.rename(columns={'Drug\\nabuse\\nviolations': 'drug_arrest'})\n",
    "    df = df.rename(columns={'Drug \\nabuse\\nviolations': 'drug_arrest'})\n",
    "    \n",
    "    # only care about drug arrest numbers by state\n",
    "    df = df.loc[:,['State','drug_arrest']]\n",
    "    \n",
    "    ############################ create state abreviation column ##############################\n",
    "    url = 'https://www.archives.gov/federal-register/electoral-college/2008/popular-vote.html'\n",
    "    df_elections_2009 = pd.read_html(url, header=1)[0]\n",
    "    df_elections_2009 = df_elections_2009.iloc[:,:8]\n",
    "    states_series = df_elections_2009.State.rename(columns={'State':'state'})\n",
    "    abreviations = pd.DataFrame(states_series)[0:51]\n",
    "    \n",
    "    ########################## drug arrest column ############################################\n",
    "    #clean up data by looking at total drug arrests\n",
    "    drug_arrests = pd.Series(df['drug_arrest'])\n",
    "    drug_arrests_by_state = [drug_arrests[index] for index in list(drug_arrests.index) if index%2 != 0];\n",
    "    drug_arrests_series = pd.Series(drug_arrests_by_state)[0:51]\n",
    "    \n",
    "    ##################### year column ########################################################\n",
    "    years = pd.Series([year]*52) #because\n",
    "    \n",
    "    ############################# include the unemployment rate column #########################\n",
    "    df_unemployement = pd.read_excel('unemployement.xlsx',skiprows=5, skipfooter=2, engine= None)\n",
    "    unemp = pd.Series(list(df_unemployement[year][2:])) #start at row index 2 because alabama is at that index\n",
    "    \n",
    "    ########################### include the sex column ####################################\n",
    "    df_sex = pd.read_csv('sex/sex'+'{}'.format(year)+'.csv', skiprows=2, skipfooter=8, engine= None)\n",
    "    df_sex = df_sex.drop('Location', axis=1)\n",
    "    #change decimals to percentages\n",
    "    df_sex *= 100\n",
    "    \n",
    "    ######################### include the race columns ######################################\n",
    "    df_race = pd.read_csv('race/race'+'{}'.format(year)+'.csv', skiprows=2, skipfooter=14)\n",
    "    df_race = df_race.drop('Location', axis=1)\n",
    "    df_race = df_race.fillna(0)\n",
    "    for i in range(0,3):\n",
    "        column = df_race.iloc[:,i]\n",
    "        for ii in range(0,len(column)):\n",
    "            try:\n",
    "                np.float64(column[ii])\n",
    "            except ValueError:\n",
    "                column[ii] = 0\n",
    "    df_race = df_race.astype(dtype='float64')\n",
    "    #change decimals to percentages\n",
    "    df_race *= 100\n",
    "    \n",
    "    ######################### include the median income columns ######################################\n",
    "    df_median = pd.read_excel('medianincome.xls', skiprows=59, skipfooter=1)\n",
    "    df_median = pd.Series(list(df_median[year][2:]))\n",
    "    #note: for 2013, it had two column values (38) and (39), we chose 39, see source file\n",
    "    \n",
    "    ######################### include the politics columns ######################################\n",
    "    url = 'https://www.archives.gov/federal-register/electoral-college/2008/popular-vote.html'\n",
    "    df_elections_2008 = pd.read_html(url, header=1)[0]\n",
    "    df_elections_2008 = df_elections_2008.iloc[:,:10]\n",
    "\n",
    "    url = 'https://www.archives.gov/federal-register/electoral-college/2012/popular-vote.html'\n",
    "    df_elections_2012 = pd.read_html(url, header=1)[0]\n",
    "    df_elections_2012 = df_elections_2012.iloc[:,:7]\n",
    "\n",
    "    url = 'https://www.archives.gov/federal-register/electoral-college/2016/popular-vote.html'\n",
    "    df_elections_2016 = pd.read_html(url, header=1)[0]\n",
    "    df_elections_2016 = df_elections_2016.iloc[:,:8]\n",
    "\n",
    "    #dem = 1 rep = 0\n",
    "    dem2008 = list(df_elections_2008['Obama\\xa0/ Biden'])\n",
    "    rep2008 = list(df_elections_2008['McCain\\xa0/ Palin'])\n",
    "    politics2008 = pd.Series(list(map(lambda dem, rep: int(dem > rep), dem2008, rep2008)))\n",
    "\n",
    "    dem2012 = list(df_elections_2012['Democratic Party(Obama\\xa0/ Biden)'])\n",
    "    rep2012 = list(df_elections_2012['Republican Party(Romney\\xa0/ Ryan)'])\n",
    "    politics2012 = pd.Series(list(map(lambda dem, rep: int(dem > rep), dem2012, rep2012)))\n",
    "\n",
    "    dem2016 = list(df_elections_2016['Democratic Party(Clinton\\xa0/ Kaine)'])\n",
    "    rep2016 = list(df_elections_2016['Republican Party(Trump\\xa0/ Pence)'])\n",
    "    politics2016 = pd.Series(list(map(lambda dem, rep: int(dem > rep), dem2016, rep2016)))\n",
    "    \n",
    "    # political views will change with each election\n",
    "    if year <= 2012:\n",
    "        # put the dataframe together with proper poltical view\n",
    "        df_all = pd.concat([years, abreviations, drug_arrests_series, df_race,\\\n",
    "                        df_median, df_sex, unemp, politics2008], axis = 1)\n",
    "    elif year > 2012 and year <= 2016:\n",
    "        # put the dataframe together with proper poltical view\n",
    "        df_all = pd.concat([years, abreviations, drug_arrests_series, df_race,\\\n",
    "                        df_median, df_sex, unemp, politics2012], axis = 1)\n",
    "    else:\n",
    "        # put the dataframe together with proper poltical view\n",
    "        df_all = pd.concat([years, abreviations, drug_arrests_series, df_race,\\\n",
    "                        df_median, df_sex, unemp, politics2016 ], axis = 1)\n",
    "    \n",
    "    #label each column properly\n",
    "    df_all.columns = ['year','state','drug_arrests', 'white', 'black',\\\n",
    "                             'hispanic', 'median_income','male_percentage',\\\n",
    "                             \"unemployment_rate\",\"politics_dem0_rep1\"] \n",
    "    df_all = df_all.drop(51)\n",
    "    return df_all\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Construct data frame for years 2014-2018 using the method defined above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/PB/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:35: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "/Users/PB/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:41: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support skipfooter; you can avoid this warning by specifying engine='python'.\n",
      "/Users/PB/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:50: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "combined = []\n",
    "for year in range(2014,2018):\n",
    "    combined.append(make_dataframe(year))\n",
    "combinedd = pd.concat(combined, axis = 0, ignore_index=True)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Add the Dependent Variable : mental health column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the population data. needed to multiple the 2017 mental health data\n",
    "# because 2017 is the only one given in percentages\n",
    "df_population_all = pd.read_csv('mental_health/nst-est2017-alldata.csv')\n",
    "population_data = df_population_all.iloc[5:56, 4:15]\n",
    "pop2017 = pd.Series(list(population_data.POPESTIMATE2017), name='pop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### Mental Health 2017\n",
    "xls2017 = pd.ExcelFile('mental_health/NSDUHsaeExcelTabs2017.xlsx')\n",
    "# rmhs = Received Mental Health Services\n",
    "df_rmhs = pd.read_excel(xls2017, 29, skiprows=10)\n",
    "df_rmhs = df_rmhs.iloc[:,1:3]\n",
    "\n",
    "# smi = Serious Mental Illness\n",
    "df_smi = pd.read_excel(xls2017, 27, skiprows=10)\n",
    "df_smi = df_smi.iloc[:,1:3]\n",
    "\n",
    "# put both mental health columns together\n",
    "mental_2017 = pd.merge(df_rmhs, df_smi, on = ['West'], how = 'outer')\n",
    "mental_2017.columns = ['state', 'rmhs_p', 'smi_p']\n",
    "mental_2017 = mental_2017.replace({'state':us_state_abbrev})\n",
    "mental_2017.insert(loc=0, column='year', value=2017)\n",
    "mental_2017.insert(loc=4, column='pop', value=pop2017)\n",
    "\n",
    "# need to multiply population for 2017 with percentage to match units for other years\n",
    "rmhs = round(mental_2017['rmhs_p'] * mental_2017['pop'] / 1000,0)\n",
    "smi = round(mental_2017['smi_p'] * mental_2017['pop'] / 1000, 0)\n",
    "\n",
    "mental_2017.insert(loc=2,value=rmhs, column='rmhs')\n",
    "mental_2017.insert(loc=3,value=smi, column='smi')\n",
    "mental_2017 = mental_2017.drop(labels=['smi_p', 'rmhs_p', 'pop'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### Mental Health 2016\n",
    "# read file for 2016\n",
    "xls2016 = pd.ExcelFile('mental_health/NSDUHsaeTotals2016.xlsx')\n",
    "\n",
    "#make rmhs column\n",
    "df_rmhs = pd.read_excel(xls2016, 28, skiprows=11)\n",
    "df_rmhs = df_rmhs.iloc[:,1:3]\n",
    "\n",
    "#make smi column\n",
    "df_smi = pd.read_excel(xls2016, 26, skiprows=11)\n",
    "df_smi = df_smi.iloc[:,1:3]\n",
    "\n",
    "#merge the two columns together\n",
    "mental_2016 = pd.merge(df_rmhs, df_smi, on = ['West'], how = 'outer')\n",
    "mental_2016.columns = ['state', 'rmhs', 'smi']\n",
    "mental_2016 = mental_2016.replace({'state':us_state_abbrev})\n",
    "mental_2016.insert(loc=0, column='year', value=2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### Mental Health 2015\n",
    "# read file for 2015\n",
    "xls2015 = pd.ExcelFile('mental_health/NSDUHsaeTotals2015.xlsx')\n",
    "\n",
    "# make smi column (note: there is no rhms data for this year)\n",
    "df_smi = pd.read_excel(xls2015, 12, skiprows=11)\n",
    "mental_2015 = df_smi.iloc[:,1:3]\n",
    "mental_2015.columns = ['state', 'smi']\n",
    "mental_2015 = mental_2015.replace({'state':us_state_abbrev})\n",
    "mental_2015.insert(loc=0, column='year', value=2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### Mental Health 2014\n",
    "#read file for 2014\n",
    "xls2014 = pd.ExcelFile('mental_health/NSDUHsaeTotals2014.xlsx')\n",
    "\n",
    "# make smi column (note: there is no rhms data for this year)\n",
    "df_smi = pd.read_excel(xls2014, 23, skiprows=10)\n",
    "mental_2014 = df_smi.iloc[:,1:3]\n",
    "mental_2014.columns = ['state', 'smi']\n",
    "mental_2014 = mental_2014.replace({'state':us_state_abbrev})\n",
    "mental_2014.insert(loc=0, column='year', value=2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge all the mental health dataframes together\n",
    "df_iter1 = pd.concat([mental_2014, mental_2015, mental_2016, mental_2017],\\\n",
    "                   axis=0, ignore_index=True, sort=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Add another independent variable : lab counts column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################## scrape from DEA Lab location site #####################\n",
    "#specify date range for the url\n",
    "date1 = '2014-01-01'\n",
    "date2 = '2017-12-31'\n",
    "dates = pd.date_range(date1, date2).tolist()\n",
    "lab_locations = []\n",
    "\n",
    "for date in dates:\n",
    "    day = date.date().day\n",
    "    month = date.date().month\n",
    "    year = date.date().year\n",
    "    \n",
    "    #scrape DEA site\n",
    "    url = requests.get('https://www.dea.gov/clan-lab?state=All&date={}%2F{}%2F{}'.format(month,day,year))\n",
    "    r = url.content\n",
    "    soup = BeautifulSoup(r,'html.parser')\n",
    "    states = soup.findAll('td',{'headers':'view-field-clan-lab-address-administrative-area-table-column'},\n",
    "            {'class':'views-field views-field-field-clan-lab-address-administrative-area is-active'})\n",
    "    \n",
    "    #needed to strip off spaces and unnecessary descriptors off states\n",
    "    states_for_date = [(state.text).strip('\\nState:').strip() for state in states]\n",
    "    years = [year]*(len(states_for_date))\n",
    "    combo = list(zip(states_for_date,years))\n",
    "    lab_locations += combo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is a list of states\n",
    "states = sorted(list(set([lab[0] for lab in lab_locations])))[1:]\n",
    "\n",
    "#count the number of labs in a state for a certain year\n",
    "lab_counts = [(year, state, lab_locations.count((state,year))) for year in range(2014,2018) for state in states]\n",
    "\n",
    "#make the other dataframe that includes lab counts\n",
    "table = []\n",
    "for tup in lab_counts:\n",
    "    #tup0 = year, tup1 = abrev, tup2 = lab count\n",
    "    table.append((tup[0], us_state_abbrev[tup[1]], tup[2]))\n",
    "\n",
    "lab_df = pd.DataFrame(table, columns = ['year', 'state','lab_count'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) Put all data frames together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge the first data frame with the other independent variable, lab_count\n",
    "df_iter2 = pd.merge(combinedd, lab_df, on = ['state','year'], how = 'outer')\n",
    "\n",
    "#merge the dataframe above with the mental health dataframe\n",
    "full_df = pd.merge(df_iter2,df_iter1, on = ['state','year'], how = 'outer')\n",
    "\n",
    "full_df.isna().sum(); #check where N/A values are. neglect rhms column N/A values\n",
    "\n",
    "full_df['lab_count'] = full_df.lab_count.fillna(0)\n",
    "full_df = full_df[['year', 'state', 'rmhs', 'smi','drug_arrests','white', 'black', 'hispanic', 'median_income', 'male_percentage','unemployment_rate', 'lab_count','politics_dem0_rep1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'full_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4b5eb6e7fc3e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfull_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfull_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtail\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'full_df' is not defined"
     ]
    }
   ],
   "source": [
    "full_df.head(), full_df.tail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.to_pickle(\"dataframe.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
